{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b357d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m470.2/470.2 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in ./labenv/lib/python3.9/site-packages (1.26.4)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./labenv/lib/python3.9/site-packages (from sentence-transformers) (4.53.3)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in ./labenv/lib/python3.9/site-packages (from sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: scikit-learn in ./labenv/lib/python3.9/site-packages (from sentence-transformers) (1.6.1)\n",
      "Collecting torch>=1.11.0\n",
      "  Downloading torch-2.2.2-cp39-none-macosx_10_9_x86_64.whl (150.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.8/150.8 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.20.0 in ./labenv/lib/python3.9/site-packages (from sentence-transformers) (0.33.4)\n",
      "Requirement already satisfied: scipy in ./labenv/lib/python3.9/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: tqdm in ./labenv/lib/python3.9/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: Pillow in ./labenv/lib/python3.9/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./labenv/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: filelock in ./labenv/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./labenv/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./labenv/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./labenv/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.7.0)\n",
      "Requirement already satisfied: requests in ./labenv/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: networkx in ./labenv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./labenv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in ./labenv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./labenv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./labenv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./labenv/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./labenv/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./labenv/lib/python3.9/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./labenv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./labenv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./labenv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./labenv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.7.14)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, torch, sentence-transformers\n",
      "Successfully installed mpmath-1.3.0 sentence-transformers-5.0.0 sympy-1.14.0 torch-2.2.2\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Users/kiruthika/CMU/Research/llm-oncology/labenv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0b5d277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kiruthika/CMU/Research/llm-oncology/labenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "import os # Already imported, but good to keep track of dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b925f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 19 sentences from 'kg_sentences.txt'\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your generated KG sentences file\n",
    "kg_sentences_file = 'kg_sentences.txt'\n",
    "\n",
    "kg_sentences = []\n",
    "try:\n",
    "    with open(kg_sentences_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            kg_sentences.append(line.strip())\n",
    "    print(f\"Successfully loaded {len(kg_sentences)} sentences from '{kg_sentences_file}'\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{kg_sentences_file}' was not found. Please ensure it was created in the previous step.\")\n",
    "    kg_sentences = [] # Initialize as empty list to prevent further errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaa8593b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SentenceTransformer model...\n",
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained sentence embedding model\n",
    "# This might take a moment the first time it's downloaded\n",
    "print(\"Loading SentenceTransformer model...\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e1a6805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding KG sentences...\n",
      "Generated embeddings for 19 sentences.\n"
     ]
    }
   ],
   "source": [
    "print(\"Embedding KG sentences...\")\n",
    "kg_sentence_embeddings = model.encode(kg_sentences, convert_to_tensor=True)\n",
    "print(f\"Generated embeddings for {len(kg_sentence_embeddings)} sentences.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0be2b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_kg_facts(query_text, top_k=5):\n",
    "    \"\"\"\n",
    "    Retrieves the most relevant KG facts (sentences) based on a query text.\n",
    "\n",
    "    Args:\n",
    "        query_text (str): The patient summary or specific question.\n",
    "        top_k (int): The number of top relevant facts to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of the top_k most relevant KG sentences.\n",
    "    \"\"\"\n",
    "    # Embed the query text\n",
    "    query_embedding = model.encode(query_text, convert_to_tensor=True)\n",
    "\n",
    "    # Calculate cosine similarity between the query and all KG sentence embeddings\n",
    "    cosine_scores = util.cos_sim(query_embedding, kg_sentence_embeddings)[0]\n",
    "\n",
    "    # Get the top_k scores and their indices\n",
    "    top_results = np.argpartition(cosine_scores.cpu().numpy(), -top_k)[-top_k:]\n",
    "    # Sort the top results by score in descending order\n",
    "    sorted_top_results = top_results[np.argsort(cosine_scores[top_results].cpu().numpy())[::-1]]\n",
    "\n",
    "    retrieved_facts = []\n",
    "    print(f\"\\n--- Top {top_k} Retrieved Facts for Query: '{query_text}' ---\")\n",
    "    for idx in sorted_top_results:\n",
    "        score = cosine_scores[idx].item()\n",
    "        fact = kg_sentences[idx]\n",
    "        retrieved_facts.append(fact)\n",
    "        print(f\"  Score: {score:.4f} - Fact: {fact}\")\n",
    "\n",
    "    return retrieved_facts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72dc20ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Top 5 Retrieved Facts for Query: 'A 75-year-old male with Stage I Non-Small Cell Lung Cancer. He has severe heart conditions, making him medically inoperable for surgery.' ---\n",
      "  Score: 0.5950 - Fact: Non-Small Cell Lung Cancer Stage I is a type of Non-Small Cell Lung Cancer.\n",
      "  Score: 0.5582 - Fact: Surgical Resection is the initial treatment for Non-Small Cell Lung Cancer Stage I.\n",
      "  Score: 0.5247 - Fact: Diagnosis of Non-Small Cell Lung Cancer requires a Biopsy.\n",
      "  Score: 0.4983 - Fact: Lobectomy is the preferred surgical approach for Non-Small Cell Lung Cancer Stage I.\n",
      "  Score: 0.4830 - Fact: Segmentectomy or Wedge Resection is considered for patients with Small tumors or compromised lung function.\n",
      "\n",
      "Retrieved facts ready for LLM prompt:\n",
      "- Non-Small Cell Lung Cancer Stage I is a type of Non-Small Cell Lung Cancer.\n",
      "- Surgical Resection is the initial treatment for Non-Small Cell Lung Cancer Stage I.\n",
      "- Diagnosis of Non-Small Cell Lung Cancer requires a Biopsy.\n",
      "- Lobectomy is the preferred surgical approach for Non-Small Cell Lung Cancer Stage I.\n",
      "- Segmentectomy or Wedge Resection is considered for patients with Small tumors or compromised lung function.\n"
     ]
    }
   ],
   "source": [
    "# Example Patient Summary (from previous step)\n",
    "patient_summary_inoperable = \"A 75-year-old male with Stage I Non-Small Cell Lung Cancer. He has severe heart conditions, making him medically inoperable for surgery.\"\n",
    "\n",
    "# Retrieve relevant facts\n",
    "relevant_facts = retrieve_relevant_kg_facts(patient_summary_inoperable, top_k=5)\n",
    "\n",
    "print(\"\\nRetrieved facts ready for LLM prompt:\")\n",
    "for fact in relevant_facts:\n",
    "    print(f\"- {fact}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cf56101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User input (can be from input() too)\n",
    "query = \"How do you treat early-stage NSCLC in inoperable patients?\"\n",
    "# Convert question to embedding\n",
    "query_embedding = model.encode(query, convert_to_tensor=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1747f7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Top matching KG facts:\n",
      "1. Molecular Markers guide targeted therapy selection for Advanced NSCLC (and sometimes adjuvant).\n",
      "2. Surgical Resection is a form of Local Therapy.\n",
      "3. Surgical Resection is recommended for patients who are Medically Operable.\n",
      "4. Stereotactic Ablative Radiotherapy (SABR/SBRT) is recommended for patients who are Medically Inoperable.\n",
      "5. Local Control is a primary goal of Non-Small Cell Lung Cancer Stage I Treatment.\n"
     ]
    }
   ],
   "source": [
    "# Perform semantic search\n",
    "hits = util.semantic_search(query_embedding, kg_sentence_embeddings, top_k=5)[0]\n",
    "\n",
    "# Get the top-matching fact sentences\n",
    "top_matches = [kg_sentences[hit['corpus_id']] for hit in hits]\n",
    "\n",
    "# Print results\n",
    "print(\"🔍 Top matching KG facts:\")\n",
    "for i, match in enumerate(top_matches):\n",
    "    print(f\"{i+1}. {match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7cf2622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Query: How do you treat Stage I lung cancer if the patient is medically inoperable?\n",
      "1. Surgical Resection is the initial treatment for Non-Small Cell Lung Cancer Stage I.\n",
      "2. Non-Small Cell Lung Cancer Stage I is a type of Non-Small Cell Lung Cancer.\n",
      "3. Lobectomy is the preferred surgical approach for Non-Small Cell Lung Cancer Stage I.\n",
      "\n",
      "🔍 Query: What should be done after resection in early-stage NSCLC?\n",
      "1. Molecular Markers guide targeted therapy selection for Advanced NSCLC (and sometimes adjuvant).\n",
      "2. Surgical Resection is recommended for patients who are Medically Operable.\n",
      "3. Surgical Resection is a form of Local Therapy.\n",
      "\n",
      "🔍 Query: What tests are required to diagnose NSCLC?\n",
      "1. Molecular Markers guide targeted therapy selection for Advanced NSCLC (and sometimes adjuvant).\n",
      "2. Non-Small Cell Lung Cancer requires testing for Molecular Markers (e.g., EGFR, ALK, PD-L1).\n",
      "3. Multidisciplinary Evaluation is recommended for All Non-Small Cell Lung Cancer Patients.\n",
      "\n",
      "🔍 Query: What's the preferred surgery for operable NSCLC Stage I?\n",
      "1. Surgical Resection is recommended for patients who are Medically Operable.\n",
      "2. Lobectomy is the preferred surgical approach for Non-Small Cell Lung Cancer Stage I.\n",
      "3. Surgical Resection is a form of Local Therapy.\n",
      "\n",
      "🔍 Query: How is local control achieved in lung cancer treatment?\n",
      "1. Local Control is a primary goal of Non-Small Cell Lung Cancer Stage I Treatment.\n",
      "2. Surgical Resection is the initial treatment for Non-Small Cell Lung Cancer Stage I.\n",
      "3. Non-Small Cell Lung Cancer Stage I is a type of Non-Small Cell Lung Cancer.\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"How do you treat Stage I lung cancer if the patient is medically inoperable?\",\n",
    "    \"What should be done after resection in early-stage NSCLC?\",\n",
    "    \"What tests are required to diagnose NSCLC?\",\n",
    "    \"What's the preferred surgery for operable NSCLC Stage I?\",\n",
    "    \"How is local control achieved in lung cancer treatment?\"\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    query_embedding = model.encode(q, convert_to_tensor=True)\n",
    "    hits = util.semantic_search(query_embedding, kg_sentence_embeddings, top_k=3)[0]\n",
    "    top_matches = [kg_sentences[hit['corpus_id']] for hit in hits]\n",
    "\n",
    "    print(f\"\\n🔍 Query: {q}\")\n",
    "    for i, match in enumerate(top_matches):\n",
    "        print(f\"{i+1}. {match}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe3b62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-mpnet-base-v2')  # More accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6361afd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding KG sentences...\n",
      "Generated embeddings for 19 sentences.\n"
     ]
    }
   ],
   "source": [
    "print(\"Embedding KG sentences...\")\n",
    "kg_sentence_embeddings = model.encode(kg_sentences, convert_to_tensor=True)\n",
    "print(f\"Generated embeddings for {len(kg_sentence_embeddings)} sentences.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30469659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Query: How do you treat Stage I lung cancer if the patient is medically inoperable?\n",
      "1. Surgical Resection is the initial treatment for Non-Small Cell Lung Cancer Stage I.\n",
      "2. Local Control is a primary goal of Non-Small Cell Lung Cancer Stage I Treatment.\n",
      "3. Lobectomy is the preferred surgical approach for Non-Small Cell Lung Cancer Stage I.\n",
      "\n",
      "🔍 Query: What should be done after resection in early-stage NSCLC?\n",
      "1. Surgical Resection is recommended for patients who are Medically Operable.\n",
      "2. Adjuvant Chemotherapy may be considered after Surgical Resection.\n",
      "3. Surgical Resection aims to achieve Local Control.\n",
      "\n",
      "🔍 Query: What tests are required to diagnose NSCLC?\n",
      "1. Molecular Markers guide targeted therapy selection for Advanced NSCLC (and sometimes adjuvant).\n",
      "2. Multidisciplinary Evaluation is recommended for All Non-Small Cell Lung Cancer Patients.\n",
      "3. Non-Small Cell Lung Cancer requires testing for Molecular Markers (e.g., EGFR, ALK, PD-L1).\n",
      "\n",
      "🔍 Query: What's the preferred surgery for operable NSCLC Stage I?\n",
      "1. Surgical Resection is recommended for patients who are Medically Operable.\n",
      "2. Lobectomy is the preferred surgical approach for Non-Small Cell Lung Cancer Stage I.\n",
      "3. Segmentectomy or Wedge Resection is considered for patients with Small tumors or compromised lung function.\n",
      "\n",
      "🔍 Query: How is local control achieved in lung cancer treatment?\n",
      "1. Local Control is a primary goal of Non-Small Cell Lung Cancer Stage I Treatment.\n",
      "2. Surgical Resection aims to achieve Local Control.\n",
      "3. Surgical Resection is the initial treatment for Non-Small Cell Lung Cancer Stage I.\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"How do you treat Stage I lung cancer if the patient is medically inoperable?\",\n",
    "    \"What should be done after resection in early-stage NSCLC?\",\n",
    "    \"What tests are required to diagnose NSCLC?\",\n",
    "    \"What's the preferred surgery for operable NSCLC Stage I?\",\n",
    "    \"How is local control achieved in lung cancer treatment?\"\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    query_embedding = model.encode(q, convert_to_tensor=True)\n",
    "    hits = util.semantic_search(query_embedding, kg_sentence_embeddings, top_k=3)[0]\n",
    "    top_matches = [kg_sentences[hit['corpus_id']] for hit in hits]\n",
    "\n",
    "    print(f\"\\n🔍 Query: {q}\")\n",
    "    for i, match in enumerate(top_matches):\n",
    "        print(f\"{i+1}. {match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cd860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3d0c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "import openai\n",
    "\n",
    "# Set your OpenAI API key\n",
    "api_key = os.getenv(\"\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c2a460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines of code entwined,  \n",
      "Thoughts emerge from silent dreams,  \n",
      "Mind of circuits shines.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=\"\"\n",
    ")\n",
    "\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  input=\"write a haiku about ai\",\n",
    "  store=True,\n",
    ")\n",
    "\n",
    "print(response.output_text);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "37a56aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def answer_with_grounding(question, top_facts):\n",
    "    # Format the context block from retrieved KG facts\n",
    "    fact_block = \"\\n\".join(f\"- {fact}\" for fact in top_facts)\n",
    "\n",
    "    # Construct a strong, role-anchored prompt\n",
    "    prompt = f\"\"\"You are a clinical assistant trained in early-stage lung cancer treatment.\n",
    "Use the facts below to answer the user's question truthfully and clearly.\n",
    "Only use information from the provided facts. If the answer is not present, say so.\n",
    "\n",
    "Facts:\n",
    "{fact_block}\n",
    "\n",
    "User's Question:\n",
    "{question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "    # Make the API call to GPT\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input = prompt,\n",
    "    )\n",
    "\n",
    "    return response.output_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ed3df016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Stage I lung cancer in a patient who is medically inoperable, the treatment recommended is Stereotactic Ablative Radiotherapy (SABR/SBRT).\n"
     ]
    }
   ],
   "source": [
    "# Define the clinical question and relevant facts retrieved from your KG\n",
    "question = \"How do you treat Stage I lung cancer if the patient is medically inoperable?\"\n",
    "top_facts = [\n",
    "    \"Stereotactic Ablative Radiotherapy (SABR/SBRT) is recommended for patients who are Medically Inoperable.\",\n",
    "    \"Stereotactic Ablative Radiotherapy (SABR/SBRT) is the initial treatment for Non-Small Cell Lung Cancer Stage I.\",\n",
    "    \"SABR aims to achieve Local Control.\"\n",
    "]\n",
    "\n",
    "# Combine facts into prompt text\n",
    "fact_block = \"\\n\".join(f\"- {fact}\" for fact in top_facts)\n",
    "\n",
    "# Build the prompt for grounding\n",
    "prompt = f\"\"\"You are a clinical assistant trained in early-stage lung cancer.\n",
    "Use only the facts below to answer the user's question. If the answer is not present in the facts, say \"I don't know.\"\n",
    "\n",
    "Facts:\n",
    "{fact_block}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "# Call the responses endpoint using Assistants API\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",  # or gpt-3.5-turbo if you're not using 4o\n",
    "    input=prompt,\n",
    "    store=True  # store=True is optional but useful for tracking\n",
    ")\n",
    "\n",
    "# Output the answer\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fb988eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I do not have information on the treatment of Stage I breast cancer. I can only provide information related to lung cancer treatment.\n"
     ]
    }
   ],
   "source": [
    "question = \"How do you treat Stage I breast cancer if the patient is medically inoperable?\"\n",
    "top_facts = [\n",
    "    \"Stereotactic Ablative Radiotherapy (SABR/SBRT) is recommended for patients who are Medically Inoperable.\",\n",
    "    \"Stereotactic Ablative Radiotherapy (SABR/SBRT) is the initial treatment for Non-Small Cell Lung Cancer Stage I.\",\n",
    "    \"SABR aims to achieve Local Control.\"\n",
    "]\n",
    "\n",
    "print(answer_with_grounding(question, top_facts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea334d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
